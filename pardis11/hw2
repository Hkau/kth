Parallel and Distributed Computing, Hand-in 2
Peter Bostr√∂m <pbos@kth.se>
2011-11-24

1. A read/increment object has initial value 0 and operations read() and inc().

- We implement a n-thread shared read/increment object I thus: I has n MRSW integer-valued registers, each with initial value 0. Upon an increment by thread i, I increments the ith MRSW register. Upon a read, thread i reads all MRSW registers one at a time and returns the sum. Show that if each MRSW register is atomic then the read/increment register is linearizable.

Atomic MRSW means that when an increment operation happens, it really happens. That's good, this will always be the linearization point for inc().

When read()-ing, if no other thread is calling inc(), any linearization point is obviously valid. If any threads are calling inc(), we have overlapping calls. How do we find a linearization point for this read() call?

During a read() call overlaps k linearization points from other inc() calls. When this happens, read() will see between 0 and k of these increments (depending on which registers are being written to, which ones are read before the write, and also when they're read). If the read() call sees i of these k increments, then we place its linearization point after the i'th but before the (i+1)th overlapping inc() linearization points. If I initially had the value m, then m+i will be return by read().

This linearization point will work fine, as a read/increment object is defined by how many inc() calls have taken effect. If read() reads l, then its linearization point will be placed after l linearization points for inc(), but before the (l+1)th for inc(), which is consistent with the value being returned. Thus the object is linearizable.

- Is this also the case when the MRSW registers are regular? Explain.

No. A counterexample can be constructed with n=2, two threads, 0 and 1. Initial value of the register is 0. Thread 1 starts an inc() operation and writes to its MRSW register. During this write() operation the register can both be read() as 0 and 1, as it is regular. At this point thread 1 zooms along and reads twice. Its own register, register 0, will show 0 twice, as it's not being written to. Register 1 will show 1 then 0 in order. This is a perfectly valid scenario, as thread 1 is still writing to that regular register.

As this is the case, thread 0 will read the read/increment-object I as 1, then 0, and we have a contradiction. This is not sequentially consistent, and thus not linearizable.


2. H&S exercise 61

Consider a distributed system where threads communicate by message-passing...

(In exercise 2 you may assume a) crash failures only and b) broadcasts are always completed. I.e. if A broadcasts m to B and C and neither B nor C fail then both B and C receive m. That is, a crash cannot cause A to send to B only and not to C (or vice versa).)

- Type A

Doesn't look possible. If we wait only for messages from n < all nodes (required to allow for crash failures), we'll run into problems. Consider the wait for n-1 case, but when no nodes have crashed: What if a node waits for and recieves n-1 messages, and none of them are the lowest? Then some nodes might agree on the lowest, while this one most certainly will not. The node cannot distinguish between if the final node has failed or not.

A working node with the lowest value may appear to be dead for a very long time, but it might just be overworked, or stuck calculating its proposed value. If we consider the working node dead, and all other nodes reach concensus from their n-1 values, but this guy will have a lower value and not agree on the same number as the other guys, and thus consensus fails, because he doesn't agree on the same number.

- Type B

Let's form consensus simply by taking the first message, everyone recieves messages in the same order. So each process broadcasts its value. As all threads recieves the messages in order (including the sender, "every thread" is clearly specified), just choose the first arriving message's value.


3. Consider carefully the lock-free list algorithm in H&S chapter 9. Explain carefully why the contains method is wait-free, and why the add and remove methods are lock-free and not wait-free.

As the list is sorted on key, and key is finite there can only be a finite number of objects inserted between the start node and the node we're looking for. As such not only can contains() always make progress, it can also always come closer to its goal (keyspace-wise, there may still be more nodes inserted between them than there was before).

The number of nodes that can be inserted between the node we're looking for and the one we're at is finite, and as such, contains() will reach it (or pass it) in a finite number of steps. As it will never restart, but only traverse the list once, contains() is wait free.

- And why the add and remove methods are lock-free and not wait-free:

If the compareAndSet calls in add/remove fails, they'll retry, but this can only be caused by some other thread that manages to progress and add/remove and return from its method call => lock-free.

The compareAndSet calls can fail infinitely many times by new threads, and as such a single thread is not guaranteed to ever finish. Thus it is not wait-free.


4. H&S exercise 117

- The add() method of the lock-free algorithm never finds a marked node with the same key. Can one modify the algorithm so that it will simply insert its new added object into the existing marked node with the same key if such a node exists in the list, thus saving the need to insert a new node?

Sure, if we change find() for the add() method to remove only nodes that are not equal to key, and to unmark any node containing the key. After unmarking it, it attempts to call the compareAndSet() like add does, to assure that the node has not been deleted (unlinked) and that its predecessor is not marked.

If this fails find() retries. This doesn't impact the lock-freedom as this would happen inside add(), but now happens within find() in an earlier stage. (A CAS similar to line 11 happens inside find(), so find() for add() may perform an add by adding back nodes containing key.)


5. Formulate a version of FloodSet for arbitrary connected graphs. That is, graphs are connected at the outset and no crash failure caises the graph to become disconnected. Prove that it works correctly.

Algorithm FloodSet:

	Broadcast own node:value pair

	for each round when any new value has been recieved:

		Broadcast all newly recieved node:value pairs

	Finally decide on the minimum value recieved

Why does it work? Round 1 you'll discover any nodes (and their original values) that's distance=1 from you, second you'll discover any nodes that are distance 2 from you, etc. So long as there's a node at distance d+1, there'll be some node at distance d (because it connects the node with d+1, which would not have been part of the component otherwise), so new messages will always be delivered to a node, until it has all of them.

Note that the node part of the pair is required, because all new values have to be labeled with who sent them, or they'd be resent ad infinitum, and we'd never know when to stop (they could have been part of an even larger network).


6. Below, try to avoid axcessive listings of e.g. p said p1 said q said v assertions. Explain how the scenarios are set up and how they work, and why they are counterexamples to Byzantine Agreement.

- a) Describe a scenario for which the simple Byzantine Agreement algorithm fails to solve consensus, for the case n = 6 and f = 2.

Byzantine processes b1, b2, regular processes p1, p2, p3, p4. We lump these together in three groups (b) = (b1, b2), (p1) = (p1, p2) and (p2) = (p3, p4).

All valid processes know which values p1, p2, p3 and p4 /really/ sent, but not whether that they're byzantine. So in the second run, (b) lies to (p1) and says that (p2) said something else than they did (p3 said "lie", p4 said "other lie"), and do the same but for (p2) about (p1). Whenever a message concering what "p3" or "p4" said, then b falsifies that message to processes in (p1), and vice versa for "p1", "p2" and (p2).

In this way, from p1's perspective p2 may be lying about what b initially said, or b is lying about what p2 said. Same for processes in p2, they'll have no way of distinguishing these groups at all.

So (b)'s goal is to make lowest-number consensus impossible. First: b1, b2 say something, k to (p1) and m to (p2), and p1,p2,p3,p4 say whatever. to (p1) (b) says that "p3" said one less than the minimum, and to (p2) we say that "p1" said two less than the actual minimum. To any correct process in (p1) it'll look like we have two processes claiming that p1 claimed min-1, and in two claiming p1's actual value. But it will also look like (b) claimed m, when (b) claimed k to them directly. Processes in (p1) cannot possibly distinguish between these claims, (b) and (p2) could be equally byzantine, so it cannot reach consensus about which value to trust.

- b) Do the same for the King algorithm.

== TODO ==

